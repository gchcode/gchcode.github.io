<p><strong>目前刚起步，详细过程会逐步完善</strong><br>接下来将介绍我的毕业论文当中，所使用到的数据的处理、分析思路、以及分析过程。</p>
<ul>
<li>［研究目的］ 新冠疫情给各国人民带来巨大浩劫，在此背景下探讨公益广告微博框架表达，在不同社会情境下的差异性，对推进我公益广告微博传播事业，提升公益广告微博传播效果具有重要意义。 </li>
<li>［研究方法］ 该研究以公益广告微博关键词，以2017年 1月1日至 2022年 12 月22日为样本的时间范围 ，共爬取138568条公益广告微博，并筛选出符合条件的样本28037条，结合新闻框架理论，从高、中、低三个层次结构展开研究，并借助机器学习与计量分析的方法，探索公益广告微博推文在常态社会与灾难情境中框架表达的差异性。 </li>
<li>［研究结论］ 研究发现，<ul>
<li>无论是何种社会情境，高层框架表达没有显著差异；</li>
<li>在中层框架中具有异同，两种社会情境下，道德框架的使用没有显著差异，在常态社会中，更倾向于使用人类利益框架，但是在危机情境下，公益广告微博更倾向于使用人事实框架。</li>
<li>在低层次框架中，指令性语言，在危机情景下增多，并且口语化程度更高。</li>
</ul>
</li>
</ul>
<h2 id="一、数据的获取与处理"><a href="#一、数据的获取与处理" class="headerlink" title="一、数据的获取与处理"></a>一、数据的获取与处理</h2><h3 id="1-github上微博爬虫程序"><a href="#1-github上微博爬虫程序" class="headerlink" title="1.github上微博爬虫程序"></a>1.github上微博爬虫程序</h3><p> <a href="https://github.com/dataabc/weiboSpider">weibospider</a></p>
<h3 id="2-源数据信息"><a href="#2-源数据信息" class="headerlink" title="2.源数据信息"></a>2.源数据信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">from matplotlib import font_manager</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;./公益广告.csv&#x27;</span>,parse_dates=[<span class="string">&#x27;发布时间&#x27;</span>],low_memory=False)</span><br><span class="line"><span class="built_in">print</span>(len(data))</span><br><span class="line"><span class="built_in">print</span>(list(data))</span><br></pre></td></tr></table></figure>


<h3 id="3-数据预处理"><a href="#3-数据预处理" class="headerlink" title="3.数据预处理"></a>3.数据预处理</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改字段名，便于后续处理</span></span><br><span class="line">data.rename(columns=&#123;<span class="string">&#x27;微博正文&#x27;</span>:<span class="string">&#x27;text&#x27;</span></span><br><span class="line">                            ,<span class="string">&#x27;转发数&#x27;</span>:<span class="string">&#x27;retweet&#x27;</span></span><br><span class="line">                            ,<span class="string">&#x27;评论数&#x27;</span>:<span class="string">&#x27;com_num&#x27;</span></span><br><span class="line">                            ,<span class="string">&#x27;点赞数&#x27;</span>:<span class="string">&#x27;like_num&#x27;</span></span><br><span class="line">                            ,<span class="string">&#x27;发布时间&#x27;</span>:<span class="string">&#x27;time&#x27;</span>&#125;</span><br><span class="line">                   ,inplace = True)</span><br><span class="line"><span class="built_in">print</span>(list(data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据去重</span></span><br><span class="line">data.drop_duplicates(subset=[<span class="string">&#x27;用户昵称&#x27;</span>,<span class="string">&#x27;text&#x27;</span>],inplace = True)</span><br><span class="line"><span class="built_in">print</span>(len(data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取需要分析的字段名：文本&amp;年份</span></span><br><span class="line">data[<span class="string">&#x27;year&#x27;</span>] =  data[<span class="string">&#x27;time&#x27;</span>].dt.year</span><br><span class="line">data_text_year = data[[<span class="string">&#x27;year&#x27;</span>,<span class="string">&#x27;text&#x27;</span>]] </span><br><span class="line"></span><br><span class="line"><span class="comment"># 异常年份数据处理 ：看到年份数据不对，找到2014年份的数据索引，并删除</span></span><br><span class="line">data_text_year[data_text_year[<span class="string">&#x27;year&#x27;</span>]==2014.0]</span><br><span class="line"><span class="built_in">print</span>(len(data_text_year)) </span><br><span class="line"></span><br><span class="line">data_text_year.drop([</span><br><span class="line">    27027</span><br><span class="line">    ,27028</span><br><span class="line">    ,27032</span><br><span class="line">    ,27033</span><br><span class="line">    ,57757</span><br><span class="line">    ,57758</span><br><span class="line">],inplace = True)</span><br><span class="line"><span class="built_in">print</span>(len(data_text_year)) </span><br></pre></td></tr></table></figure>

<h3 id="4-数据总样本选取"><a href="#4-数据总样本选取" class="headerlink" title="4.数据总样本选取"></a>4.数据总样本选取</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建副本，并删除不需要的字段</span></span><br><span class="line">raw_data = data.copy()</span><br><span class="line">raw_data.drop(columns = [<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;bid&#x27;</span>,<span class="string">&#x27;user_id&#x27;</span>,<span class="string">&#x27;头条文章url&#x27;</span>,<span class="string">&#x27;头条文章url&#x27;</span>,<span class="string">&#x27;发布工具&#x27;</span>],inplace = True)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出“text”文本中符合“【标题】+ 正文”形式的内容</span></span><br><span class="line">mask = raw_data[<span class="string">&#x27;text&#x27;</span>].str.match(<span class="string">&#x27;\【([\s\S]+?)\】&#x27;</span>, na= False)</span><br><span class="line">raw_data_new = raw_data[mask]</span><br><span class="line"><span class="built_in">print</span>(len(raw_data))</span><br><span class="line"><span class="built_in">print</span>(len(raw_data_new))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动处理样本过程不展示，最终得到比较干净的样本raw_data_final</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评论数据分布直方图</span></span><br><span class="line">sns.set_style(<span class="string">&#x27;dark&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(15,5))<span class="comment">#图像宽高</span></span><br><span class="line">font = font_manager.FontProperties(fname = r<span class="string">&#x27;C:\Windows\Fonts\STXINWEI.TTF&#x27;</span>,size = 20)</span><br><span class="line">plt.title(<span class="string">&quot;评论数据分布&quot;</span>,fontproperties = font)</span><br><span class="line">plt.grid(True)<span class="comment">#图像网格</span></span><br><span class="line">font.set_size(15)<span class="comment">#字体大小</span></span><br><span class="line"></span><br><span class="line">n_comments_year = raw_data_final.groupby(<span class="string">&#x27;year&#x27;</span>).size()</span><br><span class="line">x1 = n_comments_year.index</span><br><span class="line">y1 = n_comments_year.values</span><br><span class="line">show_ = sns.barplot(x=x1,y=y1)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;年&#x27;</span>,fontproperties = font)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<ul>
<li>研究总样本<br><img src="/./../images/%E5%85%AC%E7%9B%8A%E5%B9%BF%E5%91%8A%E5%BE%AE%E5%8D%9A%E6%9D%A1%E6%95%B0%E5%B2%81%E5%B9%B4%E4%BB%BD%E5%8F%98%E5%8C%96.png"></li>
</ul>
<h3 id="5-统计学抽样-分层抽样"><a href="#5-统计学抽样-分层抽样" class="headerlink" title="5.统计学抽样-分层抽样"></a>5.统计学抽样-分层抽样</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="comment"># 按照年进行分层抽样，样本总量为总数居的0.2，降低相同一年的数据差异，保持不同年份之间的数据差异</span></span><br><span class="line">group_ = raw_data_final.groupby(<span class="string">&#x27;year&#x27;</span>, group_keys=False).apply(lambda x: x.sample(frac=0.2,random_state = 0))</span><br><span class="line">group_year = group_.groupby(<span class="string">&#x27;year&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(len(group_))</span><br><span class="line"></span><br><span class="line">data_2017_sample = group_year.get_group(2017.0)</span><br><span class="line">data_2018_sample = group_year.get_group(2018.0)</span><br><span class="line">data_2019_sample = group_year.get_group(2019.0)</span><br><span class="line">data_2020_sample = group_year.get_group(2020.0)</span><br><span class="line">data_2021_sample = group_year.get_group(2021.0)</span><br><span class="line">data_2022_sample = group_year.get_group(2022.0)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2017年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2017_sample)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2018年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2018_sample)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2019年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2019_sample)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2020年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2020_sample)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2021年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2021_sample)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;2022年样本数据为：&#123;&#125;&#x27;</span>.format(len(data_2022_sample)))</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照社会情境划分数据，分为常态社会样本normal_society_data与危机情境样本risk_society_data</span></span><br><span class="line">normal_society_data = pd.concat(</span><br><span class="line">                        [data_2017_sample</span><br><span class="line">                         ,data_2018_sample</span><br><span class="line">                         ,data_2019_sample</span><br><span class="line">                        ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(list(normal_society_data))</span><br><span class="line"><span class="built_in">print</span>(len(normal_society_data))</span><br><span class="line"></span><br><span class="line">risk_society_data = pd.concat(</span><br><span class="line">                        [data_2020_sample</span><br><span class="line">                         ,data_2021_sample</span><br><span class="line">                         ,data_2022_sample</span><br><span class="line">                        ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(list(risk_society_data))</span><br><span class="line"><span class="built_in">print</span>(len(risk_society_data))</span><br></pre></td></tr></table></figure>
<h3 id="二、基于ti-idf的词频分析及词云"><a href="#二、基于ti-idf的词频分析及词云" class="headerlink" title="二、基于ti-idf的词频分析及词云"></a>二、基于ti-idf的词频分析及词云</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import jieba</span><br><span class="line">import jieba.analyse as analyse</span><br><span class="line">import codecs</span><br><span class="line">import wordcloud</span><br><span class="line">from PIL import Image</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词、停用词设置</span></span><br><span class="line">jieba.load_userdict(<span class="string">&#x27;./user_dict.txt&#x27;</span>)<span class="comment">#自定义添加分词 添加分词即可 格式：词语 词频 词性</span></span><br><span class="line">stopwords = [line.strip()<span class="keyword">for</span> line <span class="keyword">in</span> codecs.open(<span class="string">&#x27;D:concat_stopwords.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;utf-8&#x27;</span>).readlines()]  </span><br><span class="line">analyse.set_stop_words(<span class="string">&#x27;D:concat_stopwords.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="常态社会"><a href="#常态社会" class="headerlink" title="常态社会"></a>常态社会</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">normal_society_data_copy = normal_society_data.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词</span></span><br><span class="line">pattern = u<span class="string">&#x27;[\\s\\d,.&lt;&gt;/?:;\&#x27;</span>\&quot;[\\]&#123;&#125;()\\|~!\t<span class="string">&quot;@#$%^&amp;*\\-_=+a-zA-Z，。\n《》、？：；“”‘’｛｝【】（）…￥！—┄－]+&#x27;</span></span><br><span class="line"><span class="string">normal_society_data_copy[&#x27;cut&#x27;] = normal_society_data_copy[&#x27;text_title&#x27;].apply(lambda x:str(x))</span></span><br><span class="line"><span class="string">normal_society_data_copy[&#x27;cut&#x27;] = normal_society_data_copy[&#x27;cut&#x27;].apply(lambda x:re.sub(pattern,&#x27; &#x27;, x))</span></span><br><span class="line"><span class="string">normal_society_data_copy[&#x27;cut&#x27;] = normal_society_data_copy[&#x27;cut&#x27;].apply(lambda x:&#x27; &#x27;.join(jieba.lcut(x)))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">df_cut = pd.DataFrame(normal_society_data_copy[&#x27;cut&#x27;])</span></span><br><span class="line"><span class="string">df_cut.head()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 词频文件</span></span><br><span class="line"><span class="string">segments = []</span></span><br><span class="line"><span class="string">for index, row in df_cut.iterrows():</span></span><br><span class="line"><span class="string">    content = row[0]</span></span><br><span class="line"><span class="string">    words = analyse.textrank(content)</span></span><br><span class="line"><span class="string">    spliteStr = &#x27;&#x27;</span></span><br><span class="line"><span class="string">    for word in words:</span></span><br><span class="line"><span class="string">        if word not in stopwords:</span></span><br><span class="line"><span class="string">            segments.append(&#123;&#x27;word&#x27;:word, &#x27;count&#x27;:1&#125;)</span></span><br><span class="line"><span class="string">            spliteStr += word + &#x27; &#x27;</span></span><br><span class="line"><span class="string">dfsg = pd.DataFrame(segments)  </span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 词云生成</span></span><br><span class="line">dfword_normal = dfsg.groupby(<span class="string">&#x27;word&#x27;</span>)[<span class="string">&#x27;count&#x27;</span>].<span class="built_in">sum</span>() <span class="comment">#词频文件</span></span><br><span class="line"></span><br><span class="line">word_cloud_tag = wordcloud.WordCloud(font_path = <span class="string">&#x27;msyh.ttc&#x27;</span>,  <span class="comment">#字体</span></span><br><span class="line">                         width = 1000, <span class="comment">#宽度</span></span><br><span class="line">                         height = 700, <span class="comment">#高度</span></span><br><span class="line">                         background_color = <span class="string">&#x27;white&#x27;</span>,  <span class="comment">#背景图颜色</span></span><br><span class="line">                         max_words = 200,<span class="comment"># 词云图的最大词量</span></span><br><span class="line">                      <span class="comment">#   mask = mask,#调用背景图片</span></span><br><span class="line">                        stopwords=stopwords) <span class="comment">#使用停词表</span></span><br><span class="line">word_cloud_tag.generate_from_frequencies(dfword_normal)  <span class="comment"># 利用处理好的词频文件生成词云图   </span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(20,10))<span class="comment">#图像宽高</span></span><br><span class="line">plt.imshow(word_cloud_tag, interpolation=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/./../images/normal.png"></p>
<h4 id="危机社会"><a href="#危机社会" class="headerlink" title="危机社会"></a>危机社会</h4><p><img src="/./../images/risk.png"></p>
<h3 id="三、LDA模型"><a href="#三、LDA模型" class="headerlink" title="三、LDA模型"></a>三、LDA模型</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入需要的库</span></span><br><span class="line">import gensim</span><br><span class="line">from gensim import models, corpora</span><br><span class="line">from gensim.models import CoherenceModel</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer</span><br><span class="line">from sklearn.decomposition import NMF, LatentDirichletAllocation</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pyLDAvis</span><br><span class="line">import pyLDAvis.sklearn</span><br><span class="line">pyLDAvis.enable_notebook()</span><br></pre></td></tr></table></figure>
<h4 id="LDA模型不同K值下，一致性分数-用作参考确定合适K值"><a href="#LDA模型不同K值下，一致性分数-用作参考确定合适K值" class="headerlink" title="LDA模型不同K值下，一致性分数(用作参考确定合适K值)"></a>LDA模型不同K值下，一致性分数(用作参考确定合适K值)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">train = list(df_cut.values)</span><br><span class="line">id2word = corpora.Dictionary(train)</span><br><span class="line">corpus = [id2word.doc2bow(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> train]</span><br><span class="line"></span><br><span class="line">coherence_values = [] <span class="comment"># 一致性分数</span></span><br><span class="line">    model_list.append(lda_model)</span><br><span class="line">    coherencemodel = CoherenceModel(</span><br><span class="line">                                    model = lda_model</span><br><span class="line">                                    ,texts = train</span><br><span class="line">                                    ,dictionary = id2word</span><br><span class="line">                                    ,coherence = <span class="string">&#x27;c_v&#x27;</span></span><br><span class="line">                                )</span><br><span class="line">    coherence_values.append(round(coherencemodel.get_coherence(),3))</span><br></pre></td></tr></table></figure>
<h4 id="一致性分数随K值变化图"><a href="#一致性分数随K值变化图" class="headerlink" title="一致性分数随K值变化图"></a>一致性分数随K值变化图</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(15,5))<span class="comment">#图像宽高</span></span><br><span class="line">font = font_manager.FontProperties(fname = r<span class="string">&#x27;C:\Windows\Fonts\STXINWEI.TTF&#x27;</span>,size = 20)</span><br><span class="line">plt.title(<span class="string">&quot;折线图&quot;</span>,fontproperties = font)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.grid(True)<span class="comment">#图像网格</span></span><br><span class="line">font.set_size(15)<span class="comment">#字体大小</span></span><br><span class="line"></span><br><span class="line">x = range(1,16)</span><br><span class="line">plt.plot(x, df_score.values,marker = <span class="string">&#x27;o&#x27;</span>,markerfacecolor = <span class="string">&#x27;r&#x27;</span>,markersize = 10, markeredgecolor = <span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;num_topics&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;coherence_score&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/./../images/co_he.png"></p>
<h4 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征词向量化</span></span><br><span class="line">tf_idf_vectorizer = TfidfVectorizer(</span><br><span class="line">                                strip_accents = <span class="string">&#x27;unicode&#x27;</span></span><br><span class="line"><span class="comment">#                                ,max_features = n_features</span></span><br><span class="line">                               ,stop_words = stopwords</span><br><span class="line">                                ,max_df = 0.9 </span><br><span class="line">                               ,min_df = 10</span><br><span class="line">                                )</span><br><span class="line">tf_idf = tf_idf_vectorizer.fit_transform(normal_society_data_copy[<span class="string">&#x27;cut&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tf_idf.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型拟合及可视化</span></span><br><span class="line">n_topics = 2</span><br><span class="line">lda = LatentDirichletAllocation(</span><br><span class="line">    n_components=n_topics,</span><br><span class="line">    max_iter= 200,</span><br><span class="line">    learning_method= <span class="string">&#x27;online&#x27;</span>,</span><br><span class="line">    learning_offset= 50,</span><br><span class="line">    random_state = 2</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(lda)</span><br><span class="line">lda.fit(tf_idf)</span><br><span class="line"></span><br><span class="line">pyLDAvis.sklearn.prepare(lda, tf_idf, tf_idf_vectorizer,mds = <span class="string">&#x27;PCoA&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化文件html保存</span></span><br><span class="line"><span class="comment"># d = pyLDAvis.sklearn.prepare(lda, tf_idf, tf_idf_vectorizer,mds = &#x27;PCoA&#x27;)</span></span><br><span class="line"><span class="comment"># pyLDAvis.save_html(d,&#x27;normal.html&#x27;)</span></span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/dataabc/weiboSpider">常态社会下微博标题词LDA模型</a><br><img src="/./../images/LDA.png"></p>
<h3 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h3>